{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USING BAYESIAN OPTIMIZATION FOR HYPERPARAMETER TUNING\n",
    "\n",
    "\n",
    "- Authors: Beltr치n Aller L칩pez and Miguel L칩pez Garral칩n\n",
    "- Date: 13/12/2019\n",
    "- Email: beltran.aller@cunef.edu and m.lopez@cunef.edu\n",
    "- Institution: CUNEF\n",
    "- Version: 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before doing anything, we will import the necessaries libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt # plots\n",
    "import seaborn as sns # plots\n",
    "from scipy import stats as sts # normality test JB\n",
    "from sklearn import model_selection\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import Ridge, RidgeCV # Ridge\n",
    "from sklearn.linear_model import Lasso, LassoCV # Lasso\n",
    "from sklearn.linear_model import LogisticRegression # Log Regression\n",
    "from sklearn.metrics import r2_score # R^2\n",
    "from sklearn.model_selection import train_test_split # split data\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error # MSE\n",
    "from sklearn.preprocessing import StandardScaler # estandarization\n",
    "from sklearn import preprocessing # estandarization\n",
    "from sklearn.ensemble import IsolationForest # outliers\n",
    "from math import sqrt # sqrt\n",
    "import itertools # aplanar arrays\n",
    "import math\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.svm import SVC # SVM\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from xgboost import XGBClassifier #XGBoost\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, plot_roc_curve # ROC Curve\n",
    "from sklearn.datasets import make_classification\n",
    "import random\n",
    "random.seed(1122019)\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following variable indicates the route in which we have our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/PCA_set.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. READING THE DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is kept into the data directory. In the same folder you can find the data dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 950000 entries, 0 to 949999\n",
      "Data columns (total 42 columns):\n",
      "Component_1                            950000 non-null float64\n",
      "Component_2                            950000 non-null float64\n",
      "Component_3                            950000 non-null float64\n",
      "Component_4                            950000 non-null float64\n",
      "Component_5                            950000 non-null float64\n",
      "Component_6                            950000 non-null float64\n",
      "Component_7                            950000 non-null float64\n",
      "Component_8                            950000 non-null float64\n",
      "Component_9                            950000 non-null float64\n",
      "Component_10                           950000 non-null float64\n",
      "Component_11                           950000 non-null float64\n",
      "Component_12                           950000 non-null float64\n",
      "Component_13                           950000 non-null float64\n",
      "Component_14                           950000 non-null float64\n",
      "Component_15                           950000 non-null float64\n",
      "Component_16                           950000 non-null float64\n",
      "Component_17                           950000 non-null float64\n",
      "Component_18                           950000 non-null float64\n",
      "Component_19                           950000 non-null float64\n",
      "Component_20                           950000 non-null float64\n",
      "Component_21                           950000 non-null float64\n",
      "term_ 36 months                        950000 non-null int64\n",
      "term_ 60 months                        950000 non-null int64\n",
      "emp_length_6+ years                    950000 non-null int64\n",
      "emp_length_<= 5 years                  950000 non-null int64\n",
      "home_ownership_OTHER                   950000 non-null int64\n",
      "home_ownership_OWN                     950000 non-null int64\n",
      "home_ownership_RENT                    950000 non-null int64\n",
      "verification_status_Not Verified       950000 non-null int64\n",
      "verification_status_Source Verified    950000 non-null int64\n",
      "verification_status_Verified           950000 non-null int64\n",
      "purpose_debt_consolidation             950000 non-null int64\n",
      "purpose_home                           950000 non-null int64\n",
      "purpose_investment                     950000 non-null int64\n",
      "purpose_medical                        950000 non-null int64\n",
      "purpose_other                          950000 non-null int64\n",
      "purpose_purchase                       950000 non-null int64\n",
      "application_type_Individual            950000 non-null int64\n",
      "application_type_Joint App             950000 non-null int64\n",
      "target                                 950000 non-null int64\n",
      "desc                                   950000 non-null int64\n",
      "grade                                  950000 non-null int64\n",
      "dtypes: float64(21), int64(21)\n",
      "memory usage: 304.4 MB\n"
     ]
    }
   ],
   "source": [
    "loan.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. MODELING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We modify our exogenous variables including the categories of the dummies that we have deleted before whe we went to do the lasso regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = loan.drop(['target'], axis = 1).values\n",
    "Y = loan['target'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do the logistic regression (and the other methods) we have to split the dataset into two parts, train and test. We know that the dataset is imbalanced, we have a lot of cases of non default and a few cases os default in comparisson. To solve that problem, we will apply a method of oversampling called Smote. Smote function creates synthetic samples of the minority class making the minority class equal to the majority class. To do that Smote selects similar records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1055384, 41)\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(random_state=40, sampling_strategy = 0.4)\n",
    "X_train, Y_train = sm.fit_sample(X, Y)\n",
    "print(X_train.shape); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realise that we only do that over the train, the test must stay with the original distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain_df = pd.DataFrame(Y_train, columns = ['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_df = pd.DataFrame(X_train, columns = list(loan.drop(['target'], axis = 1).columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target\n",
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       1\n",
       "5       1\n",
       "6       0\n",
       "7       0\n",
       "8       0\n",
       "9       0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see the distribution of defaults and non defaults in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_smoted = pd.concat([xtrain_df, ytrain_df], axis = 1)\n",
    "data_smoted.to_csv('../data/data_smoted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.714286\n",
       "1    0.285714\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain_df['target'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_models(filename, model):\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Bayesian Optimization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recently, few libraries have been developed to implement Bayesian Methods for hyperparameter tuning, which is a crucial task if you want to get the best performance of a model.\n",
    "\n",
    "Bayesian optimization finds the value that minimizes an objective function by building a surrogate function.\n",
    "\n",
    "Bayesian methods differ from random or grid search in that they use past evaluation results to choose the next values to evaluate.\n",
    "\n",
    "In the case of hyperparameter optimization, the objective function is the validation error of a machine learning model using a set of hyperparameters. The aim is to find the hyperparameters that yield the lowest error on the validation set in the hope that these results generalize to the testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Support Vector Machine (SVM) is a discriminative classifier formally defined by a separating hyperplane. In other words, given labeled training data (supervised learning), the algorithm outputs an optimal hyperplane which categorizes new examples. In two dimentional space this hyperplane is a line dividing a plane in two parts where in each class lay in either side."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we define our set of parameters that are being tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_svm= {'C': (1, 10), 'gamma': (1, 10)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also we need to make the surrogate function which is going to be optimized. We define a SVM classifier with the maximun of iteration and the kerner function defined by default and the set of parameters we want tuning.\n",
    "\n",
    "The aim is to maximized the AUC and minimized the error on the validation set to use the model at the test set later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_hyper_param(C, gamma):\n",
    " \n",
    "    clf = SVC(\n",
    "        max_iter= 1000,\n",
    "        C=C,\n",
    "        kernel='linear',\n",
    "        gamma=gamma)\n",
    "    \n",
    "    return np.mean(cross_val_score(clf, X_train, Y_train, cv=3, scoring='roc_auc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |     C     |   gamma   |\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beltran\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Beltran\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Beltran\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.7544  \u001b[0m | \u001b[0m 4.753   \u001b[0m | \u001b[0m 7.483   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beltran\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Beltran\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Beltran\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.7456  \u001b[0m | \u001b[0m 1.001   \u001b[0m | \u001b[0m 3.721   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beltran\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Beltran\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Beltran\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.7514  \u001b[0m | \u001b[0m 2.321   \u001b[0m | \u001b[0m 1.831   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beltran\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Beltran\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Beltran\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.7542  \u001b[0m | \u001b[0m 2.676   \u001b[0m | \u001b[0m 4.11    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beltran\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Beltran\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Beltran\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.7544  \u001b[0m | \u001b[0m 4.571   \u001b[0m | \u001b[0m 5.849   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beltran\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Beltran\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Beltran\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.7544  \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beltran\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Beltran\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Beltran\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.7544  \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beltran\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Beltran\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Beltran\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.7544  \u001b[0m | \u001b[0m 8.988   \u001b[0m | \u001b[0m 5.179   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beltran\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Beltran\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Beltran\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.7544  \u001b[0m | \u001b[0m 6.198   \u001b[0m | \u001b[0m 1.005   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beltran\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Beltran\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Beltran\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.7544  \u001b[0m | \u001b[0m 5.455   \u001b[0m | \u001b[0m 9.999   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beltran\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Beltran\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Beltran\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.7544  \u001b[0m | \u001b[0m 7.334   \u001b[0m | \u001b[0m 5.164   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beltran\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Beltran\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Beltran\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.7544  \u001b[0m | \u001b[0m 7.275   \u001b[0m | \u001b[0m 9.995   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beltran\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Beltran\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Beltran\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.7544  \u001b[0m | \u001b[0m 7.124   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beltran\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Beltran\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Beltran\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.7544  \u001b[0m | \u001b[0m 7.561   \u001b[0m | \u001b[0m 5.563   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beltran\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Beltran\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Beltran\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.7544  \u001b[0m | \u001b[0m 7.089   \u001b[0m | \u001b[0m 9.996   \u001b[0m |\n",
      "=================================================\n",
      "Wall time: 26min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "optimizer_svm = BayesianOptimization(\n",
    "    f=svm_hyper_param,\n",
    "    pbounds=param_svm,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "optimizer_svm.maximize(n_iter = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have the best hyperparameters of our SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 0.7543539191817437,\n",
       " 'params': {'C': 4.753198042323167, 'gamma': 7.482920440979423}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer_svm.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beltran\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=4.753198042323167, break_ties=False, cache_size=200, class_weight=None,\n",
       "    coef0=0.0, decision_function_shape='ovr', degree=3, gamma=7.482920440979423,\n",
       "    kernel='linear', max_iter=1000, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "gsearch_SVM2 = SVC(max_iter=1000, C=4.753198042323167, kernel='linear', gamma=7.482920440979423)\n",
    "gsearch_SVM2.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_models('../src/Models/PCA_BO/svm_regression', gsearch_SVM2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method implemented for the SVM is going to be replicated on the other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest, in this case, is a method for classification using an ensamble of many different decision trees. In this method the decision to classify in one class or in other comes frome making the mean of the results of all the decision trees. Random Forest has small variance and is difficult to have overfitting. We use this method because a unique decision tree is so unstable and, for that reason, we train the model with a lot of decision tress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_randomf= {'max_depth' : (2,8), 'verbose': (0,1), 'cc_alpha': (0,1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomf_hyper_param(max_depth, verbose, cc_alpha):\n",
    " \n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=500,\n",
    "        bootstrap=True,\n",
    "        max_depth=max_depth,\n",
    "        criterion='gini',\n",
    "        n_jobs=-1,\n",
    "        verbose=verbose,\n",
    "        ccp_alpha=cc_alpha,\n",
    "        max_features='auto'\n",
    "    )\n",
    "    \n",
    "    return np.mean(cross_val_score(clf, X_train, Y_train, cv=3, scoring='roc_auc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | cc_alpha  | max_depth |  verbose  |\n",
      "-------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   22.3s\n",
      "[Parallel(n_jobs=-1)]: Done 218 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  4.0min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  37 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 218 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=12)]: Done 500 out of 500 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   22.3s\n",
      "[Parallel(n_jobs=-1)]: Done 218 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  4.0min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  37 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 218 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=12)]: Done 500 out of 500 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   21.3s\n",
      "[Parallel(n_jobs=-1)]: Done 218 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  4.0min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  37 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 218 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=12)]: Done 500 out of 500 | elapsed:    2.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.417   \u001b[0m | \u001b[0m 6.322   \u001b[0m | \u001b[0m 0.000114\u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done 214 tasks      | elapsed:   41.4s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  1.6min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  36 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 214 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=12)]: Done 500 out of 500 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done 214 tasks      | elapsed:   40.9s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  1.6min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  36 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 214 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=12)]: Done 500 out of 500 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=-1)]: Done 214 tasks      | elapsed:   41.3s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  1.6min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  36 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 214 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=12)]: Done 500 out of 500 | elapsed:    2.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.3023  \u001b[0m | \u001b[0m 2.881   \u001b[0m | \u001b[0m 0.09234 \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=-1)]: Done 201 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  2.7min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  33 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 201 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=12)]: Done 500 out of 500 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=-1)]: Done 201 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  2.8min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  33 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 201 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=12)]: Done 500 out of 500 | elapsed:    2.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   11.8s\n",
      "[Parallel(n_jobs=-1)]: Done 201 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  2.8min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  33 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 201 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=12)]: Done 500 out of 500 | elapsed:    2.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.1863  \u001b[0m | \u001b[0m 4.073   \u001b[0m | \u001b[0m 0.3968  \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:   12.1s\n",
      "[Parallel(n_jobs=-1)]: Done 189 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 455 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  2.8min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  30 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 189 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=12)]: Done 455 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=12)]: Done 500 out of 500 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:   11.8s\n",
      "[Parallel(n_jobs=-1)]: Done 189 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 455 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  2.8min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  30 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 189 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=12)]: Done 455 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=12)]: Done 500 out of 500 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:   12.4s\n",
      "[Parallel(n_jobs=-1)]: Done 189 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 455 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  2.8min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  30 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 189 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 455 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=12)]: Done 500 out of 500 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.5388  \u001b[0m | \u001b[0m 4.515   \u001b[0m | \u001b[0m 0.6852  \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   25.6s\n",
      "[Parallel(n_jobs=-1)]: Done 217 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  4.6min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  37 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 217 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=12)]: Done 500 out of 500 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   24.6s\n",
      "[Parallel(n_jobs=-1)]: Done 217 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  4.6min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  37 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 217 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=12)]: Done 500 out of 500 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   24.6s\n",
      "[Parallel(n_jobs=-1)]: Done 217 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  4.6min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  37 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 217 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=12)]: Done 500 out of 500 | elapsed:    2.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.2045  \u001b[0m | \u001b[0m 7.269   \u001b[0m | \u001b[0m 0.02739 \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done 177 tasks      | elapsed:   34.5s\n",
      "[Parallel(n_jobs=-1)]: Done 428 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  1.6min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  27 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 177 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 428 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=12)]: Done 500 out of 500 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done 177 tasks      | elapsed:   34.1s\n",
      "[Parallel(n_jobs=-1)]: Done 428 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  1.6min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  27 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 177 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 428 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=12)]: Done 500 out of 500 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done 177 tasks      | elapsed:   34.5s\n",
      "[Parallel(n_jobs=-1)]: Done 428 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  1.6min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  27 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 177 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 428 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=12)]: Done 500 out of 500 | elapsed:    2.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.4548  \u001b[0m | \u001b[0m 2.019   \u001b[0m | \u001b[0m 0.9845  \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:   19.4s\n",
      "[Parallel(n_jobs=-1)]: Done 178 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 429 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  4.3min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  27 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 178 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=12)]: Done 429 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=12)]: Done 500 out of 500 | elapsed:    2.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:   19.9s\n",
      "[Parallel(n_jobs=-1)]: Done 178 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 429 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  4.5min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  27 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 178 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=12)]: Done 429 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=12)]: Done 500 out of 500 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:   19.0s\n",
      "[Parallel(n_jobs=-1)]: Done 178 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 429 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  4.5min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  27 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 178 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=12)]: Done 429 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=12)]: Done 500 out of 500 | elapsed:    2.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.9248  \u001b[0m | \u001b[0m 7.989   \u001b[0m | \u001b[0m 0.9699  \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed:   20.8s\n",
      "[Parallel(n_jobs=-1)]: Done 209 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  4.6min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  35 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 209 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=12)]: Done 500 out of 500 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed:   20.7s\n",
      "[Parallel(n_jobs=-1)]: Done 209 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  4.6min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  35 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 209 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=12)]: Done 500 out of 500 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed:   20.7s\n",
      "[Parallel(n_jobs=-1)]: Done 209 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  4.6min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  35 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 209 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 500 out of 500 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.4566  \u001b[0m | \u001b[0m 7.986   \u001b[0m | \u001b[0m 0.2152  \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done 189 tasks      | elapsed:   24.9s\n",
      "[Parallel(n_jobs=-1)]: Done 455 tasks      | elapsed:   58.6s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  30 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 189 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 455 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=12)]: Done 500 out of 500 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done 189 tasks      | elapsed:   24.5s\n",
      "[Parallel(n_jobs=-1)]: Done 455 tasks      | elapsed:   58.4s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  30 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 189 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 455 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=12)]: Done 500 out of 500 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done 189 tasks      | elapsed:   25.0s\n",
      "[Parallel(n_jobs=-1)]: Done 455 tasks      | elapsed:   58.8s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  30 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 189 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 455 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=12)]: Done 500 out of 500 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.231   \u001b[0m | \u001b[0m 2.038   \u001b[0m | \u001b[0m 0.6924  \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done 177 tasks      | elapsed:   23.3s\n",
      "[Parallel(n_jobs=-1)]: Done 427 tasks      | elapsed:   55.1s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  27 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 177 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 427 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=12)]: Done 500 out of 500 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done 177 tasks      | elapsed:   23.3s\n",
      "[Parallel(n_jobs=-1)]: Done 427 tasks      | elapsed:   54.8s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  27 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 177 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 427 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=12)]: Done 500 out of 500 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done 177 tasks      | elapsed:   23.1s\n",
      "[Parallel(n_jobs=-1)]: Done 427 tasks      | elapsed:   55.5s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  27 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 177 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 427 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=12)]: Done 500 out of 500 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.8741  \u001b[0m | \u001b[0m 2.001   \u001b[0m | \u001b[0m 0.9951  \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=-1)]: Done 207 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  3.1min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 207 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 500 out of 500 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=-1)]: Done 207 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  3.2min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 207 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 500 out of 500 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   13.7s\n",
      "[Parallel(n_jobs=-1)]: Done 207 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  3.1min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 207 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 500 out of 500 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.9826  \u001b[0m | \u001b[0m 7.99    \u001b[0m | \u001b[0m 0.2582  \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done 181 tasks      | elapsed:   23.6s\n",
      "[Parallel(n_jobs=-1)]: Done 437 tasks      | elapsed:   55.9s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  28 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 181 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 437 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=12)]: Done 500 out of 500 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 181 tasks      | elapsed:   23.6s\n",
      "[Parallel(n_jobs=-1)]: Done 437 tasks      | elapsed:   56.4s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  28 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 181 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 437 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=12)]: Done 500 out of 500 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done 181 tasks      | elapsed:   23.8s\n",
      "[Parallel(n_jobs=-1)]: Done 437 tasks      | elapsed:   56.8s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  28 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 181 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 437 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=12)]: Done 500 out of 500 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.6968  \u001b[0m | \u001b[0m 2.028   \u001b[0m | \u001b[0m 0.8854  \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed:   13.1s\n",
      "[Parallel(n_jobs=-1)]: Done 193 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 463 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  3.1min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  31 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 193 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 463 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=12)]: Done 500 out of 500 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed:   13.1s\n",
      "[Parallel(n_jobs=-1)]: Done 193 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 463 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  3.0min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  31 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 193 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 463 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=12)]: Done 500 out of 500 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=-1)]: Done 193 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 463 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  3.1min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  31 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 193 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 463 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=12)]: Done 500 out of 500 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.7425  \u001b[0m | \u001b[0m 7.967   \u001b[0m | \u001b[0m 0.6052  \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done 181 tasks      | elapsed:   23.6s\n",
      "[Parallel(n_jobs=-1)]: Done 437 tasks      | elapsed:   56.5s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  28 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 181 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 437 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=12)]: Done 500 out of 500 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done 181 tasks      | elapsed:   23.5s\n",
      "[Parallel(n_jobs=-1)]: Done 437 tasks      | elapsed:   56.2s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  28 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 181 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 437 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=12)]: Done 500 out of 500 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 181 tasks      | elapsed:   23.5s\n",
      "[Parallel(n_jobs=-1)]: Done 437 tasks      | elapsed:   56.1s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  28 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 181 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 437 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=12)]: Done 500 out of 500 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.8243  \u001b[0m | \u001b[0m 2.135   \u001b[0m | \u001b[0m 0.879   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=-1)]: Done 177 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 428 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  3.1min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  27 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 177 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 428 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=12)]: Done 500 out of 500 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=-1)]: Done 177 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 428 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  3.1min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  27 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 177 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 428 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=12)]: Done 500 out of 500 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=-1)]: Done 177 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 428 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  3.1min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  27 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 177 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 428 tasks      | elapsed:    1.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.33    \u001b[0m | \u001b[0m 7.933   \u001b[0m | \u001b[0m 0.9861  \u001b[0m |\n",
      "=============================================================\n",
      "Wall time: 2h 3min 12s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done 500 out of 500 | elapsed:    1.5s finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "optimizer_randomf = BayesianOptimization(\n",
    "    f=randomf_hyper_param,\n",
    "    pbounds=param_randomf,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "optimizer_randomf.maximize(n_iter = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 0.5,\n",
       " 'params': {'cc_alpha': 0.417022004702574,\n",
       "  'max_depth': 6.321946960652949,\n",
       "  'verbose': 0.00011437481734488664}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer_randomf.max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have the best hyperparameters of our Random Forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   29.9s\n",
      "[Parallel(n_jobs=-1)]: Done 218 tasks      | elapsed:  2.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  5.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.417022004702574,\n",
       "                       class_weight=None, criterion='gini',\n",
       "                       max_depth=6.321946960652949, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
       "                       n_jobs=-1, oob_score=False, random_state=None,\n",
       "                       verbose=0.00011437481734488664, warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "gsearch_RandomForest2 = RandomForestClassifier(\n",
    "        n_estimators=500,\n",
    "        bootstrap=True,\n",
    "        max_depth=6.321946960652949,\n",
    "        criterion='gini',\n",
    "        n_jobs=-1,\n",
    "        verbose=0.00011437481734488664,\n",
    "        ccp_alpha=0.417022004702574,\n",
    "        max_features='auto'\n",
    "    )\n",
    "gsearch_RandomForest2.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(gsearch_RandomForest2.feature_importances_)\n",
    "\n",
    "list(gsearch_RandomForest2.feature_importances_)\n",
    "\n",
    "plt.bar(range(len(gsearch_RandomForest2.feature_importances_)), gsearch_RandomForest2.feature_importances_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Component_1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Component_2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Component_3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Component_4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Component_5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Component_6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Component_7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Component_8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Component_9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Component_10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Component_11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Component_12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Component_13</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Component_14</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Component_15</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Component_16</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Component_17</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Component_18</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Component_19</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Component_20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Component_21</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>term_ 36 months</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>term_ 60 months</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>emp_length_6+ years</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>emp_length_&lt;= 5 years</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>home_ownership_OTHER</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>home_ownership_OWN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>home_ownership_RENT</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>verification_status_Not Verified</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>verification_status_Source Verified</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>verification_status_Verified</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>purpose_debt_consolidation</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>purpose_home</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>purpose_investment</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>purpose_medical</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>purpose_other</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>purpose_purchase</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>application_type_Individual</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>application_type_Joint App</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>desc</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>grade</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Importance\n",
       "Component_1                                 0.0\n",
       "Component_2                                 0.0\n",
       "Component_3                                 0.0\n",
       "Component_4                                 0.0\n",
       "Component_5                                 0.0\n",
       "Component_6                                 0.0\n",
       "Component_7                                 0.0\n",
       "Component_8                                 0.0\n",
       "Component_9                                 0.0\n",
       "Component_10                                0.0\n",
       "Component_11                                0.0\n",
       "Component_12                                0.0\n",
       "Component_13                                0.0\n",
       "Component_14                                0.0\n",
       "Component_15                                0.0\n",
       "Component_16                                0.0\n",
       "Component_17                                0.0\n",
       "Component_18                                0.0\n",
       "Component_19                                0.0\n",
       "Component_20                                0.0\n",
       "Component_21                                0.0\n",
       "term_ 36 months                             0.0\n",
       "term_ 60 months                             0.0\n",
       "emp_length_6+ years                         0.0\n",
       "emp_length_<= 5 years                       0.0\n",
       "home_ownership_OTHER                        0.0\n",
       "home_ownership_OWN                          0.0\n",
       "home_ownership_RENT                         0.0\n",
       "verification_status_Not Verified            0.0\n",
       "verification_status_Source Verified         0.0\n",
       "verification_status_Verified                0.0\n",
       "purpose_debt_consolidation                  0.0\n",
       "purpose_home                                0.0\n",
       "purpose_investment                          0.0\n",
       "purpose_medical                             0.0\n",
       "purpose_other                               0.0\n",
       "purpose_purchase                            0.0\n",
       "application_type_Individual                 0.0\n",
       "application_type_Joint App                  0.0\n",
       "desc                                        0.0\n",
       "grade                                       0.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gsearch_RandomForest2.feature_importances_, loan.drop('target', axis=1).columns, columns = ['Importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_models('../src/Models/PCA_BO/random_forest_regression', gsearch_RandomForest2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost is a method for classification similar to the Random Forest model, that uses an ensamble of many different decision trees. The difference with the Random Forest is that XGBoost has more variance, it could have problems with overfitting and it usually has more accuracy with less number of estimators. In this method the cases that have failed previously in their classification have more importance for the model, so they are used again in next samples to try to classify them correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_xgboost= {'learning_rate': (0.01, 1.0),\n",
    "    'gamma': (0, 5)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost_hyper_param(learning_rate, gamma):\n",
    " \n",
    "    clf = XGBClassifier(\n",
    "        learning_rate=learning_rate,\n",
    "        n_estimators=500,\n",
    "        gamma=gamma,\n",
    "        n_jobs=-1)\n",
    "    \n",
    "    return np.mean(cross_val_score(clf, X_train, Y_train, cv=3, scoring='roc_auc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |   gamma   | learni... |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.9138  \u001b[0m | \u001b[0m 2.085   \u001b[0m | \u001b[0m 0.7231  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.9122  \u001b[0m | \u001b[0m 0.000571\u001b[0m | \u001b[0m 0.3093  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.8971  \u001b[0m | \u001b[0m 0.7338  \u001b[0m | \u001b[0m 0.1014  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.9129  \u001b[0m | \u001b[0m 0.9313  \u001b[0m | \u001b[0m 0.3521  \u001b[0m |\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m 0.915   \u001b[0m | \u001b[95m 1.984   \u001b[0m | \u001b[95m 0.5434  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.8396  \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.9104  \u001b[0m | \u001b[0m 8.87e-12\u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.9105  \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.9112  \u001b[0m | \u001b[0m 3.878   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.9109  \u001b[0m | \u001b[0m 1.215   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "=================================================\n",
      "Wall time: 47min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "optimizer_xgboost = BayesianOptimization(\n",
    "    f=xgboost_hyper_param,\n",
    "    pbounds=param_xgboost,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "optimizer_xgboost.maximize(n_iter = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 0.914974468199992,\n",
       " 'params': {'gamma': 1.9838373711533497, 'learning_rate': 0.5434285666633234}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer_xgboost.max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have the best hyperparameters of our XGBoost Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 24s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=1.9838373711533497,\n",
       "              learning_rate=0.5434285666633234, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=500, n_jobs=-1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "gsearch_XGBoost2 = XGBClassifier(\n",
    "        learning_rate=0.5434285666633234,\n",
    "        n_estimators=500,\n",
    "        gamma=1.9838373711533497,\n",
    "        n_jobs=-1)\n",
    "gsearch_XGBoost2.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00214114 0.00928956 0.00936462 0.0014107  0.01539603 0.00569542\n",
      " 0.00349576 0.01625108 0.03268584 0.00716612 0.00909483 0.01815542\n",
      " 0.004369   0.00387766 0.00668376 0.00098353 0.00265886 0.00138485\n",
      " 0.00227743 0.00169288 0.00148777 0.03174262 0.         0.05130685\n",
      " 0.         0.01933466 0.10440277 0.15968698 0.06209258 0.08652367\n",
      " 0.04393867 0.1404726  0.00579146 0.01049324 0.0016253  0.00180238\n",
      " 0.02712587 0.00777239 0.         0.00949442 0.08083127]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(gsearch_XGBoost2.feature_importances_)\n",
    "\n",
    "list(gsearch_XGBoost2.feature_importances_)\n",
    "\n",
    "plt.bar(range(len(gsearch_XGBoost2.feature_importances_)), gsearch_XGBoost2.feature_importances_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Component_1</td>\n",
       "      <td>0.002141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Component_2</td>\n",
       "      <td>0.009290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Component_3</td>\n",
       "      <td>0.009365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Component_4</td>\n",
       "      <td>0.001411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Component_5</td>\n",
       "      <td>0.015396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Component_6</td>\n",
       "      <td>0.005695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Component_7</td>\n",
       "      <td>0.003496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Component_8</td>\n",
       "      <td>0.016251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Component_9</td>\n",
       "      <td>0.032686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Component_10</td>\n",
       "      <td>0.007166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Component_11</td>\n",
       "      <td>0.009095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Component_12</td>\n",
       "      <td>0.018155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Component_13</td>\n",
       "      <td>0.004369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Component_14</td>\n",
       "      <td>0.003878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Component_15</td>\n",
       "      <td>0.006684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Component_16</td>\n",
       "      <td>0.000984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Component_17</td>\n",
       "      <td>0.002659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Component_18</td>\n",
       "      <td>0.001385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Component_19</td>\n",
       "      <td>0.002277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Component_20</td>\n",
       "      <td>0.001693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Component_21</td>\n",
       "      <td>0.001488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>term_ 36 months</td>\n",
       "      <td>0.031743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>term_ 60 months</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>emp_length_6+ years</td>\n",
       "      <td>0.051307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>emp_length_&lt;= 5 years</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>home_ownership_OTHER</td>\n",
       "      <td>0.019335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>home_ownership_OWN</td>\n",
       "      <td>0.104403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>home_ownership_RENT</td>\n",
       "      <td>0.159687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>verification_status_Not Verified</td>\n",
       "      <td>0.062093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>verification_status_Source Verified</td>\n",
       "      <td>0.086524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>verification_status_Verified</td>\n",
       "      <td>0.043939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>purpose_debt_consolidation</td>\n",
       "      <td>0.140473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>purpose_home</td>\n",
       "      <td>0.005791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>purpose_investment</td>\n",
       "      <td>0.010493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>purpose_medical</td>\n",
       "      <td>0.001625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>purpose_other</td>\n",
       "      <td>0.001802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>purpose_purchase</td>\n",
       "      <td>0.027126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>application_type_Individual</td>\n",
       "      <td>0.007772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>application_type_Joint App</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>desc</td>\n",
       "      <td>0.009494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>grade</td>\n",
       "      <td>0.080831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Importance\n",
       "Component_1                            0.002141\n",
       "Component_2                            0.009290\n",
       "Component_3                            0.009365\n",
       "Component_4                            0.001411\n",
       "Component_5                            0.015396\n",
       "Component_6                            0.005695\n",
       "Component_7                            0.003496\n",
       "Component_8                            0.016251\n",
       "Component_9                            0.032686\n",
       "Component_10                           0.007166\n",
       "Component_11                           0.009095\n",
       "Component_12                           0.018155\n",
       "Component_13                           0.004369\n",
       "Component_14                           0.003878\n",
       "Component_15                           0.006684\n",
       "Component_16                           0.000984\n",
       "Component_17                           0.002659\n",
       "Component_18                           0.001385\n",
       "Component_19                           0.002277\n",
       "Component_20                           0.001693\n",
       "Component_21                           0.001488\n",
       "term_ 36 months                        0.031743\n",
       "term_ 60 months                        0.000000\n",
       "emp_length_6+ years                    0.051307\n",
       "emp_length_<= 5 years                  0.000000\n",
       "home_ownership_OTHER                   0.019335\n",
       "home_ownership_OWN                     0.104403\n",
       "home_ownership_RENT                    0.159687\n",
       "verification_status_Not Verified       0.062093\n",
       "verification_status_Source Verified    0.086524\n",
       "verification_status_Verified           0.043939\n",
       "purpose_debt_consolidation             0.140473\n",
       "purpose_home                           0.005791\n",
       "purpose_investment                     0.010493\n",
       "purpose_medical                        0.001625\n",
       "purpose_other                          0.001802\n",
       "purpose_purchase                       0.027126\n",
       "application_type_Individual            0.007772\n",
       "application_type_Joint App             0.000000\n",
       "desc                                   0.009494\n",
       "grade                                  0.080831"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gsearch_XGBoost2.feature_importances_, loan.drop('target', axis=1).columns, columns = ['Importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_models('../src/Models/PCA_BO/xgboost_regression',gsearch_XGBoost2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian Optmization presents some limitations:\n",
    "* It does not run correctly over Random Forest.\n",
    "* As far as we know it does not allow tuning hyperparameters that are not numerical.\n",
    "* The library used is so new and it does not contain the enough documentation about what the code does especifically, although teorically we know how Bayesian Methods run. Maybe the problems observed at Random Forest could be solved if we have more knowledge about internal running of the function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian Optimization shows some advantages:\n",
    "* Is faster than Sear Grid.\n",
    "* Bayesian hyperparameter tuning uses a continually updated probability model to 띾oncentrate on promising hyperparameters by reasoning from past results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References:\n",
    "\n",
    "* https://towardsdatascience.com/automated-machine-learning-hyperparameter-tuning-in-python-dfda59b72f8a\n",
    "* https://machinelearningmastery.com/what-is-bayesian-optimization/\n",
    "* https://github.com/fmfn/BayesianOptimization\n",
    "* https://aiinpractice.com/xgboost-hyperparameter-tuning-with-bayesian-optimization/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
